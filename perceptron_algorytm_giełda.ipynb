{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2ad0659",
   "metadata": {},
   "source": [
    "### Teraz zastosujemy algorytm uczenia perceptronu dla danych z polskiej giełdy, w tym celu trzeba go nieco zmodyfikować - ograniczymy liczbę obrotów pętli i dodamy warunek zatrzymania, gdy dokładność predykcji jest u nas dość wysoka (tutaj 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9672436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60853c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activ(x):\n",
    "    \"\"\"Funkcja aktywacji signum.\"\"\"\n",
    "    if x > 0 :\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "def perceptron_epochs(x,y, func, ep = 100):\n",
    "    \"\"\"\n",
    "    Implementacja algorytmu perceptronu.\n",
    "    \n",
    "    Parametry:\n",
    "    x - macierz wejść (dane uczące)\n",
    "    y - wektor oczekiwanych wyników (etykiety)\n",
    "    func - funkcja aktywacji\n",
    "    ep - liczba obrotów pętli (domyślnie = 100)\n",
    "    \n",
    "    Zwraca:\n",
    "    w - wektor wag\n",
    "    theta - wartość biasu (przesunięcia)\n",
    "    \"\"\"\n",
    "    # Inicjalizacja wag i biasu losowymi wartościami\n",
    "    w = [random() for i in range(x.shape[1])]\n",
    "    theta = random()\n",
    "    e = 0\n",
    "    while e < ep:\n",
    "        temp = 0\n",
    "        idx = 0\n",
    "        \n",
    "        # Sprawdzamy, które przykłady są klasyfikowane poprawnie\n",
    "        for i in range(len(x)):\n",
    "            if func(np.dot(x[i], w) + theta) == y[i]:\n",
    "                temp += 1\n",
    "            else:\n",
    "                idx = i\n",
    "                break\n",
    "        # Jeżeli wszystkie przykłady są klasyfikowane poprawnie lub poprawnośc jest >= 0.8 wszystkich przykładów, kończymy\n",
    "        if temp == len(x) or temp >= 0.8 * len(x):\n",
    "            break\n",
    "        \n",
    "        # Modyfikujemy wagi i bias na podstawie pierwszego błędnie klasyfikowanego przykładu\n",
    "        w = w + y[idx] * x[idx]\n",
    "        theta = theta + y[idx]\n",
    "        e += 1\n",
    "    return w, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f719ae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych z pliku CSV\n",
    "wig20 = pd.read_csv(\"wig20_w.csv\")\n",
    "\n",
    "# Obliczenie zwrotów i opóźnień dla danych\n",
    "wig20['zwroty'] = (wig20['Zamkniecie'] - wig20['Otwarcie']) * 100 / wig20['Otwarcie']\n",
    "wig20['zam1'] = wig20['Zamkniecie'].shift(1)\n",
    "wig20['otw1'] = wig20['Otwarcie'].shift(1)\n",
    "wig20['otw2'] = wig20['Otwarcie'].shift(2)\n",
    "wig20['otw3'] = wig20['Otwarcie'].shift(3)\n",
    "wig20['otw4'] = wig20['Otwarcie'].shift(4)\n",
    "wig20['otw5'] = wig20['Otwarcie'].shift(5)\n",
    "wig20['maks1'] = wig20['Najwyzszy'].shift(1)\n",
    "wig20['min1'] = wig20['Najnizszy'].shift(1)\n",
    "\n",
    "wig20['lag1'] = (wig20['zam1'] - wig20['otw1']) * 100 / wig20['otw1']\n",
    "wig20['lag2'] = (wig20['zam1'] - wig20['otw2']) * 100 / wig20['otw2']\n",
    "wig20['lag3'] = (wig20['zam1'] - wig20['otw3']) * 100 / wig20['otw3']\n",
    "wig20['lag4'] = (wig20['zam1'] - wig20['otw4']) * 100 / wig20['otw4']\n",
    "wig20['lag5'] = (wig20['zam1'] - wig20['otw5']) * 100 / wig20['otw5']\n",
    "\n",
    "wig20['zmiana'] = np.where(wig20['zwroty'] > 0, 1, -1)\n",
    "\n",
    "# Usunięcie pierwszych pięciu wierszy z ramki danych (nie mamy dla nich wszystkich wartości zwrotów)\n",
    "wig20 = wig20.iloc[5:]\n",
    "\n",
    "# Konwersja kolumny 'Data' na typ daty\n",
    "wig20['Data'] = pd.to_datetime(wig20['Data'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4228be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alg_test(start_date_tr, end_date_tr, end_date_test, L = ['Data', 'lag1', 'zmiana']):\n",
    "    \n",
    "    \"\"\"\n",
    "    Funkcja trenująca i testująca perceptron na danych giełdowych.\n",
    "\n",
    "    Parametry:\n",
    "    start_date_tr (str): Data początkowa dla zbioru treningowego.\n",
    "    end_date_tr (str): Data końcowa dla zbioru treningowego.\n",
    "    end_date_test (str): Data końcowa dla zbioru testowego.\n",
    "    L (list): Lista kolumn, w której 'Data' musi być pierwszą kolumną, a 'zmiana' ostatnią (domyślnie ['Data', 'lag1', 'zmiana']).\n",
    "\n",
    "    Zwraca:\n",
    "    tuple: Maksymalna dokładność dla zbioru treningowego oraz testowego.\n",
    "    \"\"\"\n",
    "\n",
    "    # Utworzenie zbioru treningowego zawierającego dane przed \"2004-12-31\"\n",
    "    train = wig20[(wig20['Data'] >= start_date_tr) & (wig20['Data'] <= end_date_tr)][L]\n",
    "\n",
    "    # Konwersja danych treningowych na macierz i wyodrębnienie X i Y\n",
    "    matr = train.to_numpy()\n",
    "    X_train = matr[:, 1:len(L)-1].astype(float)\n",
    "    Y_train = matr[:, len(L)-1].astype(float)\n",
    "\n",
    "    # Utworzenie zbioru testowego zawierającego dane po \"2004-12-31\"\n",
    "    test = wig20[(wig20['Data'] > end_date_tr) & (wig20['Data'] <= end_date_test)][L]\n",
    "\n",
    "    # Konwersja danych treningowych na macierz i wyodrębnienie X i Y\n",
    "    matr = test.to_numpy()\n",
    "    X_test = matr[:, 1:len(L)-1].astype(float)\n",
    "    Y_test = matr[:, len(L)-1].astype(float)\n",
    "\n",
    "    vec_train = []\n",
    "    vec_test = []\n",
    "    for i in range(20):\n",
    "        ##dokładnośc predykcji dla zbioru treningowego\n",
    "        wagi, theta = perceptron_epochs(X_train,Y_train, activ, ep = 100000)\n",
    "        Y_pred = []\n",
    "        for i in range(len(X_train)):\n",
    "            Y_pred.append(activ(X_train[i].dot(wagi) + theta))\n",
    "        sum(Y_pred == Y_train)/len(Y_train)\n",
    "        accuracy = sum(Y_pred == Y_train) / len(Y_train)\n",
    "        vec_train.append(accuracy)\n",
    "\n",
    "        ##dokładnośc predykcji dla zbioru testowego\n",
    "        Y_pred = []                               \n",
    "        for i in range(len(X_test)):\n",
    "            Y_pred.append(activ(np.dot(X_test[i], wagi) + theta))\n",
    "        Y_pred = np.array(Y_pred)\n",
    "        Y_test = np.array(Y_test)\n",
    "        accuracy = sum(Y_pred == Y_test) / len(Y_test)\n",
    "        vec_test.append(accuracy)\n",
    "    return(\"Max_accuracy (train):\" , max(vec_train), \" Max accuracy (test):\", max(vec_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af64bf59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Max_accuracy (train):',\n",
       " 0.6785714285714286,\n",
       " ' Max accuracy (test):',\n",
       " 0.6666666666666666)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg_test('2004-06-20','2004-12-31','2005-02-28', L = ['Data', 'lag1', 'lag2', 'lag3', 'lag4', 'lag5', 'zmiana'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eeb64cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Max_accuracy (train):',\n",
       " 0.7142857142857143,\n",
       " ' Max accuracy (test):',\n",
       " 0.6666666666666666)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg_test('2004-06-20','2004-12-31','2005-02-28', L = ['Data', 'lag1', 'lag2', 'lag3', 'lag4',  'zmiana'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c84ad1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Max_accuracy (train):',\n",
       " 0.6428571428571429,\n",
       " ' Max accuracy (test):',\n",
       " 0.6666666666666666)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg_test('2004-06-20','2004-12-31','2005-02-28', L = ['Data', 'lag1', 'lag2', 'lag3', 'lag4', 'maks1','min1','zmiana'])\n",
    "\n",
    "##zmienne maks1 i min1 w tym przypadku pogorszyly wyniki na zbiorze treningowym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a109b4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Max_accuracy (train):',\n",
       " 0.6071428571428571,\n",
       " ' Max accuracy (test):',\n",
       " 0.5555555555555556)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg_test('2004-06-20','2004-12-31','2005-02-28', L = ['Data', 'lag1', 'lag2', 'lag3', 'zmiana'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d425c434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Max_accuracy (train):', 0.5, ' Max accuracy (test):', 0.7777777777777778)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg_test('2004-06-20','2004-12-31','2005-02-28', L = ['Data', 'lag1', 'lag2', 'zmiana'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dcbaacf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Max_accuracy (train):',\n",
       " 0.7142857142857143,\n",
       " ' Max accuracy (test):',\n",
       " 0.6666666666666666)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg_test('2004-06-20','2004-12-31','2005-02-28', L = ['Data', 'lag1', 'zmiana'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d82b84",
   "metadata": {},
   "source": [
    "## Do predykcji na tydzień w przód zmodyfikowałam nieco kod funkcji i tutaj dokładność przewidywań określa nam ilośc poprawnych trafień na 20 obrotów pętli (mamy w końcu tylko 1 rekord w zbiorze testowym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f71fdf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Data      lag1      lag2      lag3     lag4  zmiana\n",
      "33 2005-01-02 -0.630345  2.789237  1.461753  4.61364       1\n",
      "Na 20 obrotów pętli mamy  17 poprawnych klasyfikacji\n",
      "Max_accuracy (train): 0.7142857142857143 \n",
      " Max accuracy (test): 1.0\n"
     ]
    }
   ],
   "source": [
    "# Utworzenie zbioru treningowego zawierającego dane przed \"2004-12-31\"\n",
    "train = wig20[wig20['Data'] < '2004-12-31'][['Data', 'lag1', 'lag2', 'lag3', 'lag4', 'zmiana']]\n",
    "\n",
    "# Konwersja danych treningowych na macierz i wyodrębnienie X i Y\n",
    "matr = train.to_numpy()\n",
    "X_train = matr[:, 1:5].astype(float)\n",
    "Y_train = matr[:, 5].astype(float)\n",
    "\n",
    "# Utworzenie zbioru testowego zawierającego dane po \"2004-12-31\" i przed \"2005-01-07\"\n",
    "test = wig20[(wig20['Data'] >= '2004-12-31') & (wig20['Data'] <= '2005-01-07')][['Data', 'lag1', 'lag2', 'lag3', 'lag4','zmiana']]\n",
    "# Konwersja danych treningowych na macierz i wyodrębnienie X i Y\n",
    "matr = test.to_numpy()\n",
    "X_test = matr[:, 1:5].astype(float)\n",
    "Y_test = matr[:, 5].astype(float)\n",
    "print(test)\n",
    "\n",
    "vec_train = []\n",
    "vec_test = []\n",
    "correct_classifications = []\n",
    "for i in range(20):\n",
    "    ##dokładnośc predykcji dla zbioru treningowego\n",
    "    wagi, theta = perceptron_epochs(X_train,Y_train, activ, ep = 100000)\n",
    "    Y_pred = []\n",
    "    for i in range(len(X_train)):\n",
    "        Y_pred.append(activ(X_train[i].dot(wagi) + theta))\n",
    "    sum(Y_pred == Y_train)/len(Y_train)\n",
    "    accuracy = sum(Y_pred == Y_train) / len(Y_train)\n",
    "    vec_train.append(accuracy)\n",
    "\n",
    "    ##dokładnośc predykcji dla zbioru testowego\n",
    "    Y_pred = []                               \n",
    "    for i in range(len(X_test)):\n",
    "        Y_pred.append(activ(np.dot(X_test[i], wagi) + theta))\n",
    "    Y_pred = np.array(Y_pred)\n",
    "    Y_test = np.array(Y_test)\n",
    "    #print(Y_pred == Y_test)\n",
    "    correct_classifications.append(Y_pred == Y_test)\n",
    "    accuracy = sum(Y_pred == Y_test) / len(Y_test)\n",
    "    vec_test.append(accuracy)\n",
    "correct_classifications = np.array(correct_classifications)\n",
    "count_true = np.sum(correct_classifications)\n",
    "count_false = correct_classifications.size - count_true\n",
    "print(\"Na 20 obrotów pętli mamy \", count_true, \"poprawnych klasyfikacji\")\n",
    "print(\"Max_accuracy (train):\" , max(vec_train), \"\\n Max accuracy (test):\", max(vec_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da40f55a",
   "metadata": {},
   "source": [
    "## testujemy na miesiąc do przodu na innym okresie czasu na modelu [lag1, lag2, lag3, lag4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2980b1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Max_accuracy (train):', 0.7692307692307693, ' Max accuracy (test):', 0.5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg_test('2007-04-30','2007-10-31','2007-11-30', L = ['Data', 'lag1', 'lag2', 'lag3', 'lag4',  'zmiana'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d4c17",
   "metadata": {},
   "source": [
    "## modyfikujemy wielkość zbioru testowego i pokazujemy wzrost dokładności predykcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e166b21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Max_accuracy (train):', 0.75, ' Max accuracy (test):', 0.5428571428571428)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg_test('2004-06-20','2004-12-31','2005-08-28', L = ['Data', 'lag1', 'lag2', 'lag3', 'lag4',  'zmiana'])\n",
    "##osiem miesiacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8649a7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Max_accuracy (train):',\n",
       " 0.7142857142857143,\n",
       " ' Max accuracy (test):',\n",
       " 0.6470588235294118)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg_test('2004-06-20','2004-12-31','2005-04-28', L = ['Data', 'lag1', 'lag2', 'lag3', 'lag4',  'zmiana'])\n",
    "##cztery miesiace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ea1f11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Max_accuracy (train):',\n",
       " 0.7142857142857143,\n",
       " ' Max accuracy (test):',\n",
       " 0.6666666666666666)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg_test('2004-06-20','2004-12-31','2005-02-28', L = ['Data', 'lag1', 'lag2', 'lag3', 'lag4',  'zmiana'])\n",
    "##dwa miesiace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "339d1766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Max_accuracy (train):', 0.75, ' Max accuracy (test):', 0.8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg_test('2004-06-20','2004-12-31','2005-01-31', L = ['Data', 'lag1', 'lag2', 'lag3', 'lag4',  'zmiana'])\n",
    "##miesiac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaac20b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
